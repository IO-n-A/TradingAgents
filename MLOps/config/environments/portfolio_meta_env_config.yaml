# MLOps/config/environments/portfolio_meta_env_config.yaml
# Configuration for the PortfolioMetaExampleEnv (FinRL-Meta placeholder environment)

# General environment settings
environment_type: "PortfolioMetaExampleEnv" # Crucial for pipeline to select the correct env class
description: "Configuration for the placeholder FinRL-Meta portfolio allocation environment."

# Environment-specific parameters for PortfolioMetaExampleEnv
# These parameters will be passed to the environment's __init__ method.
initial_amount: 100000       # Initial capital for portfolio allocation (e.g., 100k USD)
transaction_cost_pct: 0.0015 # Percentage cost for transactions (e.g., 0.0015 for 0.15%)
# reward_scaling: 1.0        # Scaling factor for the reward signal (can be removed if not used by env)

# state_space_lookback is a direct parameter of PortfolioMetaExampleEnv __init__
state_space_lookback: 10     # Number of past time steps of market data to include in the observation.
                             # This should be less than the number of unique dates in the smallest data slice.

# Data and Feature Configuration
# 'df' (DataFrame) will be passed dynamically by the training pipeline.
# The environment expects 'df' to contain 'date', 'tic', and features listed in 'tech_indicator_list'.
# feature_columns: ["open", "high", "low", "close", "volume", "macd", "rsi"] # This is now hardcoded in env for example

# Technical indicators to be used by the environment.
# The training pipeline (train_rl_agent.py) uses this list to filter/ensure columns in the DataFrame.
# The PortfolioMetaExampleEnv also uses this list to structure its observation space.
# Ensure these features are generated by the data processing/feature engineering steps.
tech_indicator_list:
  - "open"
  - "high"
  - "low"
  - "close"
  - "volume"
  - "macd"   # Example technical indicator
  - "rsi"    # Example technical indicator
  # - "cci_14"
  # - "dx_14"
  # Add other technical indicators as required by the environment or strategy.
  # The PortfolioMetaExampleEnv is currently hardcoded to use ['open', 'high', 'low', 'close', 'volume', 'macd', 'rsi'].
  # This list here should match that for consistency if the env were to use it dynamically.

# Custom parameters specific to PortfolioMetaExampleEnv (passed via **kwargs in __init__)
# This section can hold any other parameters that your custom environment might need
# if they are not direct arguments of __init__.
# For PortfolioMetaExampleEnv, most key params are now direct arguments.
# custom_portfolio_config: # This key itself is not special, its contents are passed as kwargs
  # example_custom_param1: "value1"
  # example_custom_param2: 123
  # Any other parameters here would be accessible via self.env_config_kwargs in the environment.

# Parameters for environment behavior during training/evaluation
# (Some of these might be handled by the agent or training loop rather than env directly)
# max_episode_steps: 1000 # If the environment should truncate after a certain number of steps
# early_stopping_patience: 10 # For custom early stopping logic within the env (less common)

# Logging and verbosity for the environment itself
# print_verbosity: 10 # Controls how often the environment prints debug info (if implemented)

# Note: The actual DataFrame (`df`) containing stock data, `stock_dim`, etc.,
# are typically determined and passed by the training pipeline (train_rl_agent.py)
# based on the processed data it loads. This config file primarily handles
# parameters that are intrinsic to the environment's design and behavior.